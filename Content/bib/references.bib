
@inproceedings{foster_cloud_2008,
	title = {Cloud {Computing} and {Grid} {Computing} 360-{Degree} {Compared}},
	url = {http://arxiv.org/abs/0901.0131},
	doi = {10.1109/GCE.2008.4738445},
	abstract = {Cloud Computing has become another buzzword after Web 2.0. However, there are dozens of different definitions for Cloud Computing and there seems to be no consensus on what a Cloud is. On the other hand, Cloud Computing is not a completely new concept; it has intricate connection to the relatively new but thirteen-year established Grid Computing paradigm, and other relevant technologies such as utility computing, cluster computing, and distributed systems in general. This paper strives to compare and contrast Cloud Computing with Grid Computing from various angles and give insights into the essential characteristics of both.},
	urldate = {2024-09-09},
	booktitle = {2008 {Grid} {Computing} {Environments} {Workshop}},
	author = {Foster, Ian and Zhao, Yong and Raicu, Ioan and Lu, Shiyong},
	month = nov,
	year = {2008},
	keywords = {and Cluster Computing, Computer Science - Distributed, Parallel, A.1, C.2.4},
	pages = {1--10},
	annote = {arXiv:0901.0131 [cs]},
}

@misc{yin_goagent_2024,
	title = {Gödel {Agent}: {A} {Self}-{Referential} {Agent} {Framework} for {Recursive} {Self}-{Improvement}},
	shorttitle = {Gödel {Agent}},
	url = {http://arxiv.org/abs/2410.04444},
	doi = {10.48550/arXiv.2410.04444},
	abstract = {The rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of AI-driven agents across various tasks. However, existing agentic systems, whether based on fixed pipeline algorithms or pre-defined meta-learning frameworks, cannot search the whole agent design space due to the restriction of human-designed components, and thus might miss the globally optimal agent design. In this paper, we introduce G{\textbackslash}"odel Agent, a self-evolving framework inspired by the G{\textbackslash}"odel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. G{\textbackslash}"odel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of G{\textbackslash}"odel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.},
	urldate = {2024-10-14},
	publisher = {arXiv},
	author = {Yin, Xunjian and Wang, Xinyi and Pan, Liangming and Wan, Xiaojun and Wang, William Yang},
	month = oct,
	year = {2024},
	note = {arXiv:2410.04444},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/rp152k/Zotero/storage/9HLKV59J/Yin et al. - 2024 - Gödel Agent A Self-Referential Agent Framework for Recursive Self-Improvement.pdf:application/pdf;Snapshot:/home/rp152k/Zotero/storage/KUJG8AGJ/2410.html:text/html},
}

@article{noauthor_hyperspace_nodate,
	title = {Hyperspace: {A} {Peer}-to-{Peer} {Artificial} {Intelligence} {Network}},
	language = {en},
	file = {PDF:/home/rp152k/Zotero/storage/6URQ2X79/Hyperspace A Peer-to-Peer Artificial Intelligence Network.pdf:application/pdf},
}

@misc{lertpongrujikorn_object_2024,
	title = {Object as a {Service}: {Simplifying} {Cloud}-{Native} {Development} through {Serverless} {Object} {Abstraction}},
	shorttitle = {Object as a {Service}},
	url = {http://arxiv.org/abs/2408.04898},
	doi = {10.48550/arXiv.2408.04898},
	abstract = {The function-as-a-service (FaaS) paradigm is envisioned as the next generation of cloud computing systems that mitigate the burden for cloud-native application developers by abstracting them from cloud resource management. However, it does not deal with the application data aspects. As such, developers have to intervene and undergo the burden of managing the application data, often via separate cloud storage services. To further streamline cloud-native application development, in this work, we propose a new paradigm, known as Object as a Service (OaaS) that encapsulates application data and functions into the cloud object abstraction. OaaS relieves developers from resource and data management burden while offering built-in optimization features. Inspired by OOP, OaaS incorporates access modifiers and inheritance into the serverless paradigm that: (a) prevents developers from compromising the system via accidentally accessing underlying data; and (b) enables software reuse in cloud-native application development. Furthermore, OaaS natively supports dataflow semantics. It enables developers to define function workflows while transparently handling data navigation, synchronization, and parallelism issues. To establish the OaaS paradigm, we develop a platform named Oparaca that offers state abstraction for structured and unstructured data with consistency and fault-tolerant guarantees. We evaluated Oparaca under real-world settings against state-of-the-art platforms with respect to the imposed overhead, scalability, and ease of use. The results demonstrate that the object abstraction provided by OaaS can streamline flexible and scalable cloud-native application development with an insignificant overhead on the underlying serverless system.},
	urldate = {2024-09-09},
	publisher = {arXiv},
	author = {Lertpongrujikorn, Pawissanutt and Salehi, Mohsen Amini},
	month = aug,
	year = {2024},
	note = {arXiv:2408.04898 [cs]},
	keywords = {Computer Science - Software Engineering, Computer Science - Operating Systems, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/PEPQE9BN/Lertpongrujikorn and Salehi - 2024 - Object as a Service Simplifying Cloud-Native Deve.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/3RWB5Q69/2408.html:text/html},
}

@misc{jonas_cloud_2019,
	title = {Cloud {Programming} {Simplified}: {A} {Berkeley} {View} on {Serverless} {Computing}},
	shorttitle = {Cloud {Programming} {Simplified}},
	url = {http://arxiv.org/abs/1902.03383},
	doi = {10.48550/arXiv.1902.03383},
	abstract = {Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.},
	urldate = {2024-09-09},
	publisher = {arXiv},
	author = {Jonas, Eric and Schleier-Smith, Johann and Sreekanti, Vikram and Tsai, Chia-Che and Khandelwal, Anurag and Pu, Qifan and Shankar, Vaishaal and Carreira, Joao and Krauth, Karl and Yadwadkar, Neeraja and Gonzalez, Joseph E. and Popa, Raluca Ada and Stoica, Ion and Patterson, David A.},
	month = feb,
	year = {2019},
	note = {arXiv:1902.03383 [cs]},
	keywords = {Computer Science - Operating Systems},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/5U42GVFM/Jonas et al. - 2019 - Cloud Programming Simplified A Berkeley View on S.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/4XBHYBH3/1902.html:text/html},
}

@misc{varghese_cloud_2019,
	title = {Cloud {Futurology}},
	url = {http://arxiv.org/abs/1902.03656},
	doi = {10.48550/arXiv.1902.03656},
	abstract = {The Cloud has become integral to most Internet-based applications and user gadgets. This article provides a brief history of the Cloud and presents a researcher's view of the prospects for innovating at the infrastructure, middleware, and application and delivery levels of the already crowded Cloud computing stack.},
	urldate = {2024-09-09},
	publisher = {arXiv},
	author = {Varghese, Blesson and Leitner, Philipp and Ray, Suprio and Chard, Kyle and Barker, Adam and Elkhatib, Yehia and Herry, Herry and Hong, Cheol-Ho and Singer, Jeremy and Tso, Fung Po and Yoneki, Eiko and Zhani, Mohamed-Faten},
	month = feb,
	year = {2019},
	note = {arXiv:1902.03656 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: Accepted to IEEE Computer, 2019},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/3SFQ82BX/Varghese et al. - 2019 - Cloud Futurology.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/UGM8DRHY/1902.html:text/html},
}

@misc{ramadan_role_2024,
	title = {The {Role} of {Artificial} {Intelligence} and {Machine} {Learning} in {Software} {Testing}},
	url = {http://arxiv.org/abs/2409.02693},
	doi = {10.48550/arXiv.2409.02693},
	abstract = {Artificial Intelligence (AI) and Machine Learning (ML) have significantly impacted various industries, including software development. Software testing, a crucial part of the software development lifecycle (SDLC), ensures the quality and reliability of software products. Traditionally, software testing has been a labor-intensive process requiring significant manual effort. However, the advent of AI and ML has transformed this landscape by introducing automation and intelligent decision-making capabilities. AI and ML technologies enhance the efficiency and effectiveness of software testing by automating complex tasks such as test case generation, test execution, and result analysis. These technologies reduce the time required for testing and improve the accuracy of defect detection, ultimately leading to higher quality software. AI can predict potential areas of failure by analyzing historical data and identifying patterns, which allows for more targeted and efficient testing. This paper explores the role of AI and ML in software testing by reviewing existing literature, analyzing current tools and techniques, and presenting case studies that demonstrate the practical benefits of these technologies. The literature review provides a comprehensive overview of the advancements in AI and ML applications in software testing, highlighting key methodologies and findings from various studies. The analysis of current tools showcases the capabilities of popular AI-driven testing tools such as Eggplant AI, Test.ai, Selenium, Appvance, Applitools Eyes, Katalon Studio, and Tricentis Tosca, each offering unique features and advantages. Case studies included in this paper illustrate real-world applications of AI and ML in software testing, showing significant improvements in testing efficiency, accuracy, and overall software quality.},
	urldate = {2024-09-09},
	publisher = {arXiv},
	author = {Ramadan, Ahmed and Yasin, Husam and Pektas, Burhan},
	month = sep,
	year = {2024},
	note = {arXiv:2409.02693 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/FGVSTR8X/Ramadan et al. - 2024 - The Role of Artificial Intelligence and Machine Le.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/73QW5ILT/2409.html:text/html},
}

@misc{astekin_comparative_2024,
	title = {A {Comparative} {Study} on {Large} {Language} {Models} for {Log} {Parsing}},
	url = {http://arxiv.org/abs/2409.02474},
	doi = {10.1145/3674805.3686684},
	abstract = {Background: Log messages provide valuable information about the status of software systems. This information is provided in an unstructured fashion and automated approaches are applied to extract relevant parameters. To ease this process, log parsing can be applied, which transforms log messages into structured log templates. Recent advances in language models have led to several studies that apply ChatGPT to the task of log parsing with promising results. However, the performance of other state-of-the-art large language models (LLMs) on the log parsing task remains unclear. Aims: In this study, we investigate the current capability of state-of-the-art LLMs to perform log parsing. Method: We select six recent LLMs, including both paid proprietary (GPT-3.5, Claude 2.1) and four free-to-use open models, and compare their performance on system logs obtained from a selection of mature open-source projects. We design two different prompting approaches and apply the LLMs on 1, 354 log templates across 16 different projects. We evaluate their effectiveness, in the number of correctly identified templates, and the syntactic similarity between the generated templates and the ground truth. Results: We found that free-to-use models are able to compete with paid models, with CodeLlama extracting 10\% more log templates correctly than GPT-3.5. Moreover, we provide qualitative insights into the usability of language models (e.g., how easy it is to use their responses). Conclusions: Our results reveal that some of the smaller, free-to-use LLMs can considerably assist log parsing compared to their paid proprietary competitors, especially code-specialized models.},
	urldate = {2024-09-09},
	author = {Astekin, Merve and Hort, Max and Moonen, Leon},
	month = sep,
	year = {2024},
	note = {arXiv:2409.02474 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering},
	annote = {Comment: Accepted for publication in the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM '24)},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/2QVCQWHG/Astekin et al. - 2024 - A Comparative Study on Large Language Models for L.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/U4ZMLUQB/2409.html:text/html},
}

@misc{guo_deepseek-coder_2024,
	title = {{DeepSeek}-{Coder}: {When} the {Large} {Language} {Model} {Meets} {Programming} -- {The} {Rise} of {Code} {Intelligence}},
	shorttitle = {{DeepSeek}-{Coder}},
	url = {https://arxiv.org/abs/2401.14196v2},
	abstract = {The rapid development of large language models has revolutionized code intelligence in software development. However, the predominance of closed-source models has restricted extensive research and development. To address this, we introduce the DeepSeek-Coder series, a range of open-source code models with sizes from 1.3B to 33B, trained from scratch on 2 trillion tokens. These models are pre-trained on a high-quality project-level code corpus and employ a fill-in-the-blank task with a 16K window to enhance code generation and infilling. Our extensive evaluations demonstrate that DeepSeek-Coder not only achieves state-of-the-art performance among open-source code models across multiple benchmarks but also surpasses existing closed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models are under a permissive license that allows for both research and unrestricted commercial use.},
	language = {en},
	urldate = {2024-09-08},
	journal = {arXiv.org},
	author = {Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi, Xiao and Wu, Y. and Li, Y. K. and Luo, Fuli and Xiong, Yingfei and Liang, Wenfeng},
	month = jan,
	year = {2024},
	file = {Full Text PDF:/home/rp152k/Zotero/storage/N729SIHI/Guo et al. - 2024 - DeepSeek-Coder When the Large Language Model Meet.pdf:application/pdf},
}

@misc{mersha_explainable_2024,
	title = {Explainable {Artificial} {Intelligence}: {A} {Survey} of {Needs}, {Techniques}, {Applications}, and {Future} {Direction}},
	shorttitle = {Explainable {Artificial} {Intelligence}},
	url = {https://arxiv.org/abs/2409.00265v1},
	abstract = {Artificial intelligence models encounter significant challenges due to their black-box nature, particularly in safety-critical domains such as healthcare, finance, and autonomous vehicles. Explainable Artificial Intelligence (XAI) addresses these challenges by providing explanations for how these models make decisions and predictions, ensuring transparency, accountability, and fairness. Existing studies have examined the fundamental concepts of XAI, its general principles, and the scope of XAI techniques. However, there remains a gap in the literature as there are no comprehensive reviews that delve into the detailed mathematical representations, design methodologies of XAI models, and other associated aspects. This paper provides a comprehensive literature review encompassing common terminologies and definitions, the need for XAI, beneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI methods in different application areas. The survey is aimed at XAI researchers, XAI practitioners, AI model developers, and XAI beneficiaries who are interested in enhancing the trustworthiness, transparency, accountability, and fairness of their AI models.},
	language = {en},
	urldate = {2024-09-08},
	journal = {arXiv.org},
	author = {Mersha, Melkamu and Lam, Khang and Wood, Joseph and AlShami, Ali and Kalita, Jugal},
	month = aug,
	year = {2024},
	doi = {10.1016/j.neucom.2024.128111},
	file = {Full Text PDF:/home/rp152k/Zotero/storage/XNX3MQB8/Mersha et al. - 2024 - Explainable Artificial Intelligence A Survey of N.pdf:application/pdf},
}

@misc{zhang_no_2024,
	title = {No {Man} is an {Island}: {Towards} {Fully} {Automatic} {Programming} by {Code} {Search}, {Code} {Generation} and {Program} {Repair}},
	shorttitle = {No {Man} is an {Island}},
	url = {https://arxiv.org/abs/2409.03267v1},
	abstract = {Automatic programming attempts to minimize human intervention in the generation of executable code, and has been a long-standing challenge in the software engineering community. To advance automatic programming, researchers are focusing on three primary directions: (1) code search that reuses existing code snippets from external databases; (2) code generation that produces new code snippets from natural language; and (3) program repair that refines existing code snippets by fixing detected bugs. Despite significant advancements, the effectiveness of state-of-the-art techniques is still limited, such as the usability of searched code and the correctness of generated code. Motivated by the real-world programming process, where developers usually use various external tools to aid their coding processes, such as code search engines and code testing tools, in this work, we propose {\textbackslash}toolname\{\}, an automatic programming framework that leverages recent large language models (LLMs) to integrate the three research areas to address their inherent limitations. In particular, our framework first leverages different code search strategies to retrieve similar code snippets, which are then used to further guide the code generation process of LLMs. Our framework further validates the quality of generated code by compilers and test cases, and constructs repair prompts to query LLMs for generating correct patches. We conduct preliminary experiments to demonstrate the potential of our framework, {\textbackslash}eg helping CodeLlama solve 267 programming problems with an improvement of 62.53{\textbackslash}\%. As a generic framework, {\textbackslash}toolname\{\} can integrate various code search, generation, and repair tools, combining these three research areas together for the first time. More importantly, it demonstrates the potential of using traditional SE tools to enhance the usability of LLMs in automatic programming.},
	language = {en},
	urldate = {2024-09-08},
	journal = {arXiv.org},
	author = {Zhang, Quanjun and Fang, Chunrong and Shang, Ye and Zhang, Tongke and Yu, Shengcheng and Chen, Zhenyu},
	month = sep,
	year = {2024},
	file = {Full Text PDF:/home/rp152k/Zotero/storage/Y746HTV6/Zhang et al. - 2024 - No Man is an Island Towards Fully Automatic Progr.pdf:application/pdf},
}

@misc{cvetkovic_dirigent_2024,
	title = {Dirigent: {Lightweight} {Serverless} {Orchestration}},
	shorttitle = {Dirigent},
	url = {https://arxiv.org/abs/2404.16393v1},
	abstract = {While Function as a Service (FaaS) platforms can initialize function sandboxes on worker nodes in 10-100s of milliseconds, the latency to schedule functions in real FaaS clusters can be orders of magnitude higher. We find that the current approach of building FaaS cluster managers on top of legacy orchestration systems like Kubernetes leads to high scheduling delay at high sandbox churn, which is typical in FaaS clusters. While generic cluster managers use hierarchical abstractions and multiple internal components to manage and reconcile state with frequent persistent updates, this becomes a bottleneck for FaaS, where cluster state frequently changes as sandboxes are created on the critical path of requests. Based on our root cause analysis of performance issues in existing FaaS cluster managers, we propose Dirigent, a clean-slate system architecture for FaaS orchestration with three key principles. First, Dirigent optimizes internal cluster manager abstractions to simplify state management. Second, it eliminates persistent state updates on the critical path of function invocations, leveraging the fact that FaaS abstracts sandboxes from users to relax exact state reconstruction guarantees. Finally, Dirigent runs monolithic control and data planes to minimize internal communication overheads and maximize throughput. We compare Dirigent to state-of-the-art FaaS platforms and show that Dirigent reduces 99th percentile per-function scheduling latency for a production workload by 2.79x compared to AWS Lambda and can spin up 2500 sandboxes per second at low latency, which is 1250x more than with Knative.},
	language = {en},
	urldate = {2024-09-07},
	journal = {arXiv.org},
	author = {Cvetković, Lazar and Costa, François and Djokic, Mihajlo and Friedman, Michal and Klimovic, Ana},
	month = apr,
	year = {2024},
	file = {Full Text PDF:/home/rp152k/Zotero/storage/YXK2X5XS/Cvetković et al. - 2024 - Dirigent Lightweight Serverless Orchestration.pdf:application/pdf},
}

@misc{thijsman_trusting_2024,
	title = {Trusting the {Cloud}-{Native} {Edge}: {Remotely} {Attested} {Kubernetes} {Workers}},
	shorttitle = {Trusting the {Cloud}-{Native} {Edge}},
	url = {http://arxiv.org/abs/2405.10131},
	doi = {10.48550/arXiv.2405.10131},
	abstract = {A Kubernetes cluster typically consists of trusted nodes, running within the confines of a physically secure datacenter. With recent advances in edge orchestration, this is no longer the case. This poses a new challenge: how can we trust a device that an attacker has physical access to? This paper presents an architecture and open-source implementation that securely enrolls edge devices as trusted Kubernetes worker nodes. By providing boot attestation rooted in a hardware Trusted Platform Module, a strong base of trust is provided. A new custom controller directs a modified version of Keylime to cross the cloud-edge gap and securely deliver unique cluster credentials required to enroll an edge worker. The controller dynamically grants and revokes these credentials based on attestation events, preventing a possibly compromised node from accessing sensitive cluster resources. We provide both a qualitative and a quantitative evaluation of the architecture. The qualitative scenarios prove its ability to attest and enroll an edge device with role-based access control (RBAC) permissions that dynamically adjust to attestation events. The quantitative evaluation reflects an average of 10.28 seconds delay incurred on the startup time of the edge node due to attestation for a total average enrollment time of 20.91 seconds. The presented architecture thus provides a strong base of trust, securing a physically exposed edge device and paving the way for a robust and resilient edge computing ecosystem.},
	urldate = {2024-09-07},
	publisher = {arXiv},
	author = {Thijsman, Jordi and Sebrechts, Merlijn and De Turck, Filip and Volckaert, Bruno},
	month = may,
	year = {2024},
	note = {arXiv:2405.10131 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	annote = {Comment: Pre-print of article accepted to IEEE ICCCN 2024},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/FWNQPCGP/Thijsman et al. - 2024 - Trusting the Cloud-Native Edge Remotely Attested .pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/5PCRPWUA/2405.html:text/html},
}

@misc{de_palma_funless_2024,
	title = {{FunLess}: {Functions}-as-a-{Service} for {Private} {Edge} {Cloud} {Systems}},
	shorttitle = {{FunLess}},
	url = {http://arxiv.org/abs/2405.21009},
	doi = {10.48550/arXiv.2405.21009},
	abstract = {We present FunLess, a Function-as-a-Service (FaaS) platform tailored for the private edge cloud system. FunLess responds to recent trends that advocate for extending the coverage of serverless computing to private edge cloud systems and enhancing latency, security, and privacy while improving resource usage. Unlike existing solutions that rely on containers for function invocation, FunLess leverages WebAssembly (Wasm) as its runtime environment. Wasm's lightweight, sandboxed runtime is crucial to have functions run on constrained devices at the edge. Moreover, the advantages of using Wasm in FunLess include a consistent development and deployment environment for users and function portability (write once, run everywhere) We validate FunLess under different deployment scenarios, characterised by the presence/absence of constrained-resource devices (Raspberry Pi 3B+) and the (in)accessibility of container orchestration technologies - Kubernetes. We compare FunLess with three production-ready, widely adopted open-source FaaS platforms - OpenFaaS, Fission, and Knative. Our benchmarks confirm that FunLess is a proper solution for FaaS private edge cloud systems since it achieves performance comparable to the considered FaaS alternatives while it is the only fully-deployable alternative on constrained-resource devices, thanks to its small memory footprint.},
	urldate = {2024-09-07},
	publisher = {arXiv},
	author = {De Palma, Giuseppe and Giallorenzo, Saverio and Mauro, Jacopo and Trentin, Matteo and Zavattaro, Gianluigi},
	month = may,
	year = {2024},
	note = {arXiv:2405.21009 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/5QG9ZBAW/De Palma et al. - 2024 - FunLess Functions-as-a-Service for Private Edge C.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/2LVP2YTR/2405.html:text/html},
}

@article{gupta_columnar_2021,
	title = {Columnar storage and list-based processing for graph database management systems},
	volume = {14},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3476249.3476297},
	doi = {10.14778/3476249.3476297},
	abstract = {We revisit column-oriented storage and query processing techniques in the context of contemporary graph database management systems (GDBMSs). Similar to column-oriented RDBMSs, GDBMSs support read-heavy analytical workloads that however have fundamentally different data access patterns than traditional analytical workloads. We first derive a set of desiderata for optimizing storage and query processors of GDBMS based on their access patterns. We then present the design of columnar storage, compression, and query processing techniques based on these desiderata. In addition to showing direct integration of existing techniques from columnar RDBMSs, we also propose novel ones that are optimized for GDBMSs. These include a novel list-based query processor, which avoids expensive data copies of traditional block-based processors under many-to-many joins, a new data structure we call singleindexed edge property pages and an accompanying edge ID scheme, and a new application of Jacobson’s bit vector index for compressing NULL values and empty lists. We integrated our techniques into the GraphflowDB in-memory GDBMS. Through extensive experiments, we demonstrate the scalability and query performance benefits of our techniques.},
	language = {en},
	number = {11},
	urldate = {2024-09-07},
	journal = {Proceedings of the VLDB Endowment},
	author = {Gupta, Pranjal and Mhedhbi, Amine and Salihoglu, Semih},
	month = jul,
	year = {2021},
	pages = {2491--2504},
	file = {Gupta et al. - 2021 - Columnar storage and list-based processing for gra.pdf:/home/rp152k/Zotero/storage/EAE8LYB9/Gupta et al. - 2021 - Columnar storage and list-based processing for gra.pdf:application/pdf},
}

@misc{ueno_migrating_2024,
	title = {Migrating {Existing} {Container} {Workload} to {Kubernetes} -- {LLM} {Based} {Approach} and {Evaluation}},
	url = {http://arxiv.org/abs/2408.11428},
	doi = {10.48550/arXiv.2408.11428},
	abstract = {Although Kubernetes has become a widespread open-source system that automates the management of containerized applications, its complexity can be a significant barrier, particularly for application developers unfamiliar with it. One approach employs large language models (LLMs) to assist developers in generating Kubernetes manifests; however it is currently impossible to determine whether the output satisfies given specifications and is comprehensible. In this study, we proposed a benchmarking method for evaluating the effectiveness of LLMs in synthesizing manifests, using the Compose specification -- a standard widely adopted by application developers -- as input. The proposed benchmarking method revealed that LLMs generally produce accurate results that compensate for simple specification gaps. However, we also observed that inline comments for readability were often omitted, and completion accuracy was low for atypical inputs with unclear intentions.},
	urldate = {2024-08-23},
	publisher = {arXiv},
	author = {Ueno, Masaru and Uchiumi, Tetsuya},
	month = aug,
	year = {2024},
	note = {arXiv:2408.11428 [cs]},
	keywords = {Computer Science - Software Engineering},
	annote = {Comment: submitted to ICSME 2024 Industry Track},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/3M5HNIV6/Ueno and Uchiumi - 2024 - Migrating Existing Container Workload to Kubernete.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/ATBNY8SK/2408.html:text/html},
}

@misc{kalwarowskyj_parallel_2023,
	title = {Parallel {Neural} {Networks} in {Golang}},
	url = {http://arxiv.org/abs/2304.09590},
	doi = {10.48550/arXiv.2304.09590},
	abstract = {This paper describes the design and implementation of parallel neural networks (PNNs) with the novel programming language Golang. We follow in our approach the classical Single-Program Multiple-Data (SPMD) model where a PNN is composed of several sequential neural networks, which are trained with a proportional share of the training dataset. We used for this purpose the MNIST dataset, which contains binary images of handwritten digits. Our analysis focusses on different activation functions and optimizations in the form of stochastic gradients and initialization of weights and biases. We conduct a thorough performance analysis, where network configurations and different performance factors are analyzed and interpreted. Golang and its inherent parallelization support proved very well for parallel neural network simulation by considerable decreased processing times compared to sequential variants.},
	urldate = {2024-08-23},
	publisher = {arXiv},
	author = {Kalwarowskyj, Daniela and Schikuta, Erich},
	month = apr,
	year = {2023},
	note = {arXiv:2304.09590 [cs]},
	keywords = {68T07, Computer Science - Neural and Evolutionary Computing, I.2, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: Extended version of paper Daniela Kalwarowskyj and Erich Schikuta, SPMD-based Neural Network Simulation with Golang, published at International Conference on Computational Science (ICCS) 2023},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/HBBHLAUI/Kalwarowskyj and Schikuta - 2023 - Parallel Neural Networks in Golang.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/V6W59QV2/2304.html:text/html},
}

@misc{petryk_importance_2024,
	title = {On the {Importance} of {Reproducibility} of {Experimental} {Results} {Especially} in the {Domain} of {Security}},
	url = {http://arxiv.org/abs/2407.06760},
	doi = {10.1109/MECO62516.2024.10577919},
	abstract = {Security especially in the fields of IoT, industrial automation and critical infrastructure is paramount nowadays and a hot research topic. In order to ensure confidence in research results they need to be reproducible. In the past we reported [18] that in many publications important information such as details about the equipment used are missing. In this paper we report on our own experiments that we run to verify the parameters reported in the datasheets that came along with our experimental equipment. Our results show that there are significant discrepancies between the datasheets and the real world data. These deviations concern accuracy of positions, movements, duration of laser shots etc. In order to improve reproducibility of results we therefore argue on the one hand that research groups verify the data given in datasheets of equipment they use and on the other hand that they provide measurement set-up parameters in globally accepted units such as cm, seconds, etc.},
	urldate = {2024-07-10},
	author = {Petryk, Dmytro and Kabin, Ievgen and Langendörfer, Peter and Dyka, Zoya},
	month = jul,
	year = {2024},
	note = {arXiv:2407.06760 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Hardware Architecture},
	annote = {Comment: 4 figures, 3 tables},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/HJHIXPCN/Petryk et al. - 2024 - On the Importance of Reproducibility of Experiment.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/6BBHTLMP/2407.html:text/html},
}

@misc{qiao_we-math_2024,
	title = {We-{Math}: {Does} {Your} {Large} {Multimodal} {Model} {Achieve} {Human}-like {Mathematical} {Reasoning}?},
	shorttitle = {We-{Math}},
	url = {http://arxiv.org/abs/2407.01284},
	doi = {10.48550/arXiv.2407.01284},
	abstract = {Visual mathematical reasoning, as a fundamental visual reasoning ability, has received widespread attention from the Large Multimodal Models (LMMs) community. Existing benchmarks, such as MathVista and MathVerse, focus more on the result-oriented performance but neglect the underlying principles in knowledge acquisition and generalization. Inspired by human-like mathematical reasoning, we introduce WE-MATH, the first benchmark specifically designed to explore the problem-solving principles beyond end-to-end performance. We meticulously collect and categorize 6.5K visual math problems, spanning 67 hierarchical knowledge concepts and five layers of knowledge granularity. We decompose composite problems into sub-problems according to the required knowledge concepts and introduce a novel four-dimensional metric, namely Insufficient Knowledge (IK), Inadequate Generalization (IG), Complete Mastery (CM), and Rote Memorization (RM), to hierarchically assess inherent issues in LMMs' reasoning process. With WE-MATH, we conduct a thorough evaluation of existing LMMs in visual mathematical reasoning and reveal a negative correlation between solving steps and problem-specific performance. We confirm the IK issue of LMMs can be effectively improved via knowledge augmentation strategies. More notably, the primary challenge of GPT-4o has significantly transitioned from IK to IG, establishing it as the first LMM advancing towards the knowledge generalization stage. In contrast, other LMMs exhibit a marked inclination towards Rote Memorization - they correctly solve composite problems involving multiple knowledge concepts yet fail to answer sub-problems. We anticipate that WE-MATH will open new pathways for advancements in visual mathematical reasoning for LMMs. The WE-MATH data and evaluation code are available at https://github.com/We-Math/We-Math.},
	urldate = {2024-07-07},
	publisher = {arXiv},
	author = {Qiao, Runqi and Tan, Qiuna and Dong, Guanting and Wu, Minhui and Sun, Chong and Song, Xiaoshuai and GongQue, Zhuoma and Lei, Shanglin and Wei, Zhe and Zhang, Miaoxuan and Qiao, Runfeng and Zhang, Yifan and Zong, Xiao and Xu, Yida and Diao, Muxi and Bao, Zhimin and Li, Chen and Zhang, Honggang},
	month = jul,
	year = {2024},
	note = {arXiv:2407.01284 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Symbolic Computation},
	annote = {Comment: Work in progress},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/IU5B49TG/Qiao et al. - 2024 - We-Math Does Your Large Multimodal Model Achieve .pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/NSFPNXAV/2407.html:text/html},
}

@misc{zhang_new_2023,
	title = {A {New} {Information} {Theory} of {Certainty} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/2304.12833},
	doi = {10.48550/arXiv.2304.12833},
	abstract = {Claude Shannon coined entropy to quantify the uncertainty of a random distribution for communication coding theory. We observe that the uncertainty nature of entropy also limits its direct usage in mathematical modeling. Therefore we propose a new concept troenpy,as the canonical dual of entropy, to quantify the certainty of the underlying distribution. We demonstrate two applications in machine learning. The first is for the classical document classification, we develop a troenpy based weighting scheme to leverage the document class label. The second is a self-troenpy weighting scheme for sequential data and show that it can be easily included in neural network based language models and achieve dramatic perplexity reduction. We also define quantum troenpy as the dual of the Von Neumann entropy to quantify the certainty of quantum systems.},
	urldate = {2024-07-07},
	publisher = {arXiv},
	author = {Zhang, Arthur Jun},
	month = apr,
	year = {2023},
	note = {arXiv:2304.12833 [cs, math]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Information Theory},
	annote = {Comment: 24 pages, 3 figures, 1 table},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/RREK5VQY/Zhang - 2023 - A New Information Theory of Certainty for Machine .pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/MS3Y5DB3/2304.html:text/html},
}

@misc{vaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2024-06-19},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: 15 pages, 5 figures},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/335MFALG/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/KR7F69YM/1706.html:text/html},
}

@misc{yi_neural-symbolic_2019,
	title = {Neural-{Symbolic} {VQA}: {Disentangling} {Reasoning} from {Vision} and {Language} {Understanding}},
	shorttitle = {Neural-{Symbolic} {VQA}},
	url = {http://arxiv.org/abs/1810.02338},
	doi = {10.48550/arXiv.1810.02338},
	abstract = {We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering (NS-VQA) system first recovers a structural scene representation from the image and a program trace from the question. It then executes the program on the scene representation to obtain an answer. Incorporating symbolic structure as prior knowledge offers three unique advantages. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an accuracy of 99.8\% on the CLEVR dataset. Second, the model is more data- and memory-efficient: it performs well after learning on a small number of training data; it can also encode an image into a compact representation, requiring less storage than existing methods for offline question answering. Third, symbolic program execution offers full transparency to the reasoning process; we are thus able to interpret and diagnose each execution step.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {Yi, Kexin and Wu, Jiajun and Gan, Chuang and Torralba, Antonio and Kohli, Pushmeet and Tenenbaum, Joshua B.},
	month = jan,
	year = {2019},
	note = {arXiv:1810.02338 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: NeurIPS 2018 (spotlight). The first two authors contributed equally to this work. Project page: http://nsvqa.csail.mit.edu},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/WQ8SJ528/Yi et al. - 2019 - Neural-Symbolic VQA Disentangling Reasoning from .pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/9CIDLP4A/1810.html:text/html},
}

@misc{battaglia_relational_2018,
	title = {Relational inductive biases, deep learning, and graph networks},
	url = {http://arxiv.org/abs/1806.01261},
	doi = {10.48550/arXiv.1806.01261},
	abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
	month = oct,
	year = {2018},
	note = {arXiv:1806.01261 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/S6TRQ9KR/Battaglia et al. - 2018 - Relational inductive biases, deep learning, and gr.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/JRHFDMQ4/1806.html:text/html},
}

@misc{lamb_graph_2021,
	title = {Graph {Neural} {Networks} {Meet} {Neural}-{Symbolic} {Computing}: {A} {Survey} and {Perspective}},
	shorttitle = {Graph {Neural} {Networks} {Meet} {Neural}-{Symbolic} {Computing}},
	url = {http://arxiv.org/abs/2003.00330},
	doi = {10.48550/arXiv.2003.00330},
	abstract = {Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. Graph Neural Networks (GNN) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as its relationship to current developments in neural-symbolic computing.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {Lamb, Luis C. and Garcez, Artur and Gori, Marco and Prates, Marcelo and Avelar, Pedro and Vardi, Moshe},
	month = jun,
	year = {2021},
	note = {arXiv:2003.00330 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Logic in Computer Science},
	annote = {Comment: Updated version, draft of accepted IJCAI2020 Survey Paper},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/2SP4FU4E/Lamb et al. - 2021 - Graph Neural Networks Meet Neural-Symbolic Computi.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/URE2YKP9/2003.html:text/html},
}

@misc{noauthor_neuro-symbolic_nodate,
	title = {Neuro-{Symbolic} {Artificial} {Intelligence} - workshops},
	url = {https://people.cs.ksu.edu/~hitzler/nesy/},
	urldate = {2024-06-17},
	file = {Neuro-Symbolic Artificial Intelligence:/home/rp152k/Zotero/storage/63DNPJFW/nesy.html:text/html},
}

@misc{de_raedt_statistical_2020,
	title = {From {Statistical} {Relational} to {Neuro}-{Symbolic} {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2003.08316},
	doi = {10.48550/arXiv.2003.08316},
	abstract = {Neuro-symbolic and statistical relational artificial intelligence both integrate frameworks for learning with logical reasoning. This survey identifies several parallels across seven different dimensions between these two fields. These cannot only be used to characterize and position neuro-symbolic artificial intelligence approaches but also to identify a number of directions for further research.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {De Raedt, Luc and Dumančić, Sebastijan and Manhaeve, Robin and Marra, Giuseppe},
	month = mar,
	year = {2020},
	note = {arXiv:2003.08316 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/U4FGFF77/De Raedt et al. - 2020 - From Statistical Relational to Neuro-Symbolic Arti.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/8IVPLMHU/2003.html:text/html},
}

@misc{bottou_machine_2011,
	title = {From {Machine} {Learning} to {Machine} {Reasoning}},
	url = {http://arxiv.org/abs/1102.1808},
	doi = {10.48550/arXiv.1102.1808},
	abstract = {A plausible definition of "reasoning" could be "algebraically manipulating previously acquired knowledge in order to answer a new question". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labeled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated "all-purpose" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {Bottou, Leon},
	month = feb,
	year = {2011},
	note = {arXiv:1102.1808 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 15 pages - fix broken pagination in v2},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/MJ6VVSW2/Bottou - 2011 - From Machine Learning to Machine Reasoning.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/GYZQ2VD2/1102.html:text/html},
}

@article{hitzler_neural-symbolic_2020,
	title = {Neural-symbolic integration and the {Semantic} {Web}},
	volume = {11},
	issn = {22104968, 15700844},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-190368},
	doi = {10.3233/SW-190368},
	language = {en},
	number = {1},
	urldate = {2024-06-17},
	journal = {Semantic Web},
	author = {Hitzler, Pascal and Bianchi, Federico and Ebrahimi, Monireh and Sarker, Md Kamruzzaman},
	editor = {Janowicz, Krzysztof},
	month = jan,
	year = {2020},
	pages = {3--11},
	file = {Hitzler et al. - 2020 - Neural-symbolic integration and the Semantic Web.pdf:/home/rp152k/Zotero/storage/TXQTYC6N/Hitzler et al. - 2020 - Neural-symbolic integration and the Semantic Web.pdf:application/pdf},
}

@misc{garcez_neurosymbolic_2020,
	title = {Neurosymbolic {AI}: {The} 3rd {Wave}},
	shorttitle = {Neurosymbolic {AI}},
	url = {http://arxiv.org/abs/2012.05876},
	doi = {10.48550/arXiv.2012.05876},
	abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {Garcez, Artur d'Avila and Lamb, Luis C.},
	month = dec,
	year = {2020},
	note = {arXiv:2012.05876 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.4, I.2.6},
	annote = {Comment: 37 pages},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/62RGF8PB/Garcez and Lamb - 2020 - Neurosymbolic AI The 3rd Wave.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/3QTEEPKH/2012.html:text/html},
}

@misc{sheth_neurosymbolic_2023,
	title = {Neurosymbolic {AI} -- {Why}, {What}, and {How}},
	url = {http://arxiv.org/abs/2305.00813},
	doi = {10.48550/arXiv.2305.00813},
	abstract = {Humans interact with the environment using a combination of perception - transforming sensory inputs from their environment into symbols, and cognition - mapping symbols to knowledge about the environment for supporting abstraction, reasoning by analogy, and long-term planning. Human perception-inspired machine perception, in the context of AI, refers to large-scale pattern recognition from raw data using neural networks trained using self-supervised learning objectives such as next-word prediction or object recognition. On the other hand, machine cognition encompasses more complex computations, such as using knowledge of the environment to guide reasoning, analogy, and long-term planning. Humans can also control and explain their cognitive functions. This seems to require the retention of symbolic mappings from perception outputs to knowledge about their environment. For example, humans can follow and explain the guidelines and safety constraints driving their decision-making in safety-critical applications such as healthcare, criminal justice, and autonomous driving. This article introduces the rapidly emerging paradigm of Neurosymbolic AI combines neural networks and knowledge-guided symbolic approaches to create more capable and flexible AI systems. These systems have immense potential to advance both algorithm-level (e.g., abstraction, analogy, reasoning) and application-level (e.g., explainable and safety-constrained decision-making) capabilities of AI systems.},
	urldate = {2024-06-17},
	publisher = {arXiv},
	author = {Sheth, Amit and Roy, Kaushik and Gaur, Manas},
	month = may,
	year = {2023},
	note = {arXiv:2305.00813 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: To appear in IEEE Intelligent Systems},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/XKHCL4IW/Sheth et al. - 2023 - Neurosymbolic AI -- Why, What, and How.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/JWNHUYEJ/2305.html:text/html},
}

@misc{noauthor_rabbit_nodate,
	title = {‪{Rabbit}: {Efficient} {Comparison} for {Secure} {Multi}-{Party} {Computation}‬},
	shorttitle = {‪{Rabbit}},
	url = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l21zXnAAAAAJ&sortby=pubdate&citation_for_view=l21zXnAAAAAJ:Zph67rFs4hoC},
	abstract = {‪E Makri, D Rotaru, F Vercauteren, S Wagh, 2021‬ - ‪Cited by 5‬},
	urldate = {2021-11-20},
}

@misc{yahuda_lindell_primer_nodate,
	title = {A {Primer} in {Secure} {Multiparty} {Computation}},
	url = {https://www.unboundtech.com/wp-content/uploads/2020/09/Unbound_Tech_A_Primer_in_Secure_Multiparty_Computation_MPC.pdf},
	author = {Yahuda, Lindell},
	file = {Yahuda, Lindell - A_Primer_in_Secure_Multiparty_Computation_MPC.pdf:/home/rp152k/Zotero/storage/KWTBZFCC/Yahuda, Lindell - A_Primer_in_Secure_Multiparty_Computation_MPC.pdf:application/pdf},
}

@misc{noauthor_cryptology_nodate,
	title = {Cryptology {ePrint} {Archive}: {Report} 2020/300 - {Secure} {Multiparty} {Computation} ({MPC})},
	url = {https://eprint.iacr.org/2020/300},
	urldate = {2021-11-19},
	file = {Cryptology ePrint Archive\: Report 2020/300 - Secure Multiparty Computation (MPC):/home/rp152k/Zotero/storage/WIH5PDTM/300.html:text/html},
}

@article{viand_sok_2021,
	title = {{SoK}: {Fully} {Homomorphic} {Encryption} {Compilers}},
	shorttitle = {{SoK}},
	url = {http://arxiv.org/abs/2101.07078},
	abstract = {Fully Homomorphic Encryption (FHE) allows a third party to perform arbitrary computations on encrypted data, learning neither the inputs nor the computation results. Hence, it provides resilience in situations where computations are carried out by an untrusted or potentially compromised party. This powerful concept was first conceived by Rivest et al. in the 1970s. However, it remained unrealized until Craig Gentry presented the first feasible FHE scheme in 2009. The advent of the massive collection of sensitive data in cloud services, coupled with a plague of data breaches, moved highly regulated businesses to increasingly demand confidential and secure computing solutions. This demand, in turn, has led to a recent surge in the development of FHE tools. To understand the landscape of recent FHE tool developments, we conduct an extensive survey and experimental evaluation to explore the current state of the art and identify areas for future development. In this paper, we survey, evaluate, and systematize FHE tools and compilers. We perform experiments to evaluate these tools' performance and usability aspects on a variety of applications. We conclude with recommendations for developers intending to develop FHE-based applications and a discussion on future directions for FHE tools development.},
	urldate = {2021-11-17},
	journal = {arXiv:2101.07078 [cs]},
	author = {Viand, Alexander and Jattke, Patrick and Hithnawi, Anwar},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.07078
version: 1},
	keywords = {Computer Science - Cryptography and Security},
	annote = {Comment: 13 pages, to appear in IEEE Symposium on Security and Privacy 2021},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/N2LQML23/Viand et al. - 2021 - SoK Fully Homomorphic Encryption Compilers.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/TKVA2A2C/2101.html:text/html},
}

@article{nguyen_leep_2020,
	title = {{LEEP}: {A} {New} {Measure} to {Evaluate} {Transferability} of {Learned} {Representations}},
	shorttitle = {{LEEP}},
	url = {http://arxiv.org/abs/2002.12462},
	abstract = {We introduce a new measure to evaluate the transferability of representations learned by classifiers. Our measure, the Log Expected Empirical Prediction (LEEP), is simple and easy to compute: when given a classifier trained on a source data set, it only requires running the target data set through this classifier once. We analyze the properties of LEEP theoretically and demonstrate its effectiveness empirically. Our analysis shows that LEEP can predict the performance and convergence speed of both transfer and meta-transfer learning methods, even for small or imbalanced data. Moreover, LEEP outperforms recently proposed transferability measures such as negative conditional entropy and H scores. Notably, when transferring from ImageNet to CIFAR100, LEEP can achieve up to 30\% improvement compared to the best competing method in terms of the correlations with actual transfer accuracy.},
	urldate = {2021-10-01},
	journal = {arXiv:2002.12462 [cs, stat]},
	author = {Nguyen, Cuong V. and Hassner, Tal and Seeger, Matthias and Archambeau, Cedric},
	month = aug,
	year = {2020},
	note = {arXiv: 2002.12462},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Published at the International Conference on Machine Learning (ICML) 2020},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/BVKGGYNR/Nguyen et al. - 2020 - LEEP A New Measure to Evaluate Transferability of.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/AK7NKYD8/2002.html:text/html},
}

@article{dalskov_secure_2020,
	title = {Secure {Evaluation} of {Quantized} {Neural} {Networks}},
	volume = {2020},
	issn = {2299-0984},
	url = {http://arxiv.org/abs/1910.12435},
	doi = {10.2478/popets-2020-0077},
	abstract = {We investigate two questions in this paper: First, we ask to what extent "MPC friendly" models are already supported by major Machine Learning frameworks such as TensorFlow or PyTorch. Prior works provide protocols that only work on fixed-point integers and specialized activation functions, two aspects that are not supported by popular Machine Learning frameworks, and the need for these specialized model representations means that it is hard, and often impossible, to use e.g., TensorFlow to design, train and test models that later have to be evaluated securely. Second, we ask to what extent the functionality for evaluating Neural Networks already exists in general-purpose MPC frameworks. These frameworks have received more scrutiny, are better documented and supported on more platforms. Furthermore, they are typically flexible in terms of the threat model they support. In contrast, most secure evaluation protocols in the literature are targeted to a specific threat model and their implementations are only a "proof-of-concept", making it very hard for their adoption in practice. We answer both of the above questions in a positive way: We observe that the quantization techniques supported by both TensorFlow, PyTorch and MXNet can provide models in a representation that can be evaluated securely; and moreover, that this evaluation can be performed by a general purpose MPC framework. We perform extensive benchmarks to understand the exact trade-offs between different corruption models, network sizes and efficiency. These experiments provide an interesting insight into cost between active and passive security, as well as honest and dishonest majority. Our work shows then that the separating line between existing ML frameworks and existing MPC protocols may be narrower than implicitly suggested by previous works.},
	number = {4},
	urldate = {2021-09-12},
	journal = {Proceedings on Privacy Enhancing Technologies},
	author = {Dalskov, Anders and Escudero, Daniel and Keller, Marcel},
	month = oct,
	year = {2020},
	note = {arXiv: 1910.12435},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	pages = {355--375},
	annote = {Comment: 22 pages},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/GJLYQGMX/Dalskov et al. - 2020 - Secure Evaluation of Quantized Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/827RD3SA/1910.html:text/html},
}

@article{hennig_how_2013,
	title = {How to find an appropriate clustering for mixed-type variables with application to socio-economic stratification: {How} to {Find} an {Appropriate} {Clustering}},
	volume = {62},
	issn = {00359254},
	shorttitle = {How to find an appropriate clustering for mixed-type variables with application to socio-economic stratification},
	url = {http://doi.wiley.com/10.1111/j.1467-9876.2012.01066.x},
	doi = {10.1111/j.1467-9876.2012.01066.x},
	abstract = {Data with mixed-type (metric–ordinal–nominal) variables are typical for social stratiﬁcation, i.e. partitioning a population into social classes. Approaches to cluster such data are compared, namely a latent class mixture model assuming local independence and dissimilarity-based methods such as k -medoids. The design of an appropriate dissimilarity measure and the estimation of the number of clusters are discussed as well, comparing the Bayesian information criterion with dissimilarity-based criteria. The comparison is based on a philosophy of cluster analysis that connects the problem of a choice of a suitable clustering method closely to the application by considering direct interpretations of the implications of the methodology. The application of this philosophy to economic data from the 2007 US Survey of Consumer Finances demonstrates techniques and decisions required to obtain an interpretable clustering. The clustering is shown to be signiﬁcantly more structured than a suitable null model. One result is that the data-based strata are not as strongly connected to occupation categories as is often assumed in the literature.},
	language = {en},
	number = {3},
	urldate = {2021-06-30},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Hennig, Christian and Liao, Tim F.},
	month = may,
	year = {2013},
	pages = {309--369},
	file = {Hennig and Liao - 2013 - How to find an appropriate clustering for mixed-ty.pdf:/home/rp152k/Zotero/storage/CNT4ZUFC/Hennig and Liao - 2013 - How to find an appropriate clustering for mixed-ty.pdf:application/pdf},
}

@misc{noauthor_23_nodate,
	title = {2.3. {Clustering} — scikit-learn 0.24.2 documentation},
	url = {https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation},
	urldate = {2021-06-29},
}

@article{gehrke_rainforest_nodate,
	title = {{RainForest} - a {Framework} for {Fast} {Decision} {Tree} {Construction} of {Large} {Datasets}},
	abstract = {Classification of large datasetsis an important data mining problem. Many classification algorithms have been proposed in the literature, but studies have shown that so far no algorithm uniformly outperforms all other algorithms in terms of quality. In this paper, we present a unifying framework for decision tree classifiers that separatesthescalability aspectsof algorithms for constructing a decision tree from the central features that determinethe quality of the tree. This generic algorithm is easyto instantiatewith specific algorithms from the literature (including C4.5, CART, CHAID, FACT,ID3 andextensions,SLIQ, Sprint and QUEST).},
	language = {en},
	author = {Gehrke, Johannes and Ramakrishnan, Raghu and Gantit, Venkatesh},
	pages = {12},
	file = {Gehrke et al. - RainForest - a Framework for Fast Decision Tree Co.pdf:/home/rp152k/Zotero/storage/WKXKBPEF/Gehrke et al. - RainForest - a Framework for Fast Decision Tree Co.pdf:application/pdf},
}

@article{shafer_sprint_nodate,
	title = {{SPRINT}: {A} {Scalable} {Parallel} {Classifier} for {Data} {Mining}},
	abstract = {Classification is an important data mining problem. Although classification is a wellstudied problem, most of the current classification algorithms require that all or a portion of the the entire dataset remain permanently in memory. This limits their suitability for mining over large databases. We present a new decision-tree-based classification algorithm, called SPRINT that removes all of the memory restrictions, and is fast and scalable. The algorithm has also been designed to be easily parallelized, allowing many processors to work together to build a single consistent model. This parallelization, also presented here, exhibits excellent scalability as well. The combination of these characteristics makes the proposed algorithm an ideal tool for data mining.},
	language = {en},
	author = {Shafer, John and Agrawal, Rakeeh and Mehta, Manish},
	pages = {12},
	file = {Shafer et al. - SPRINT A Scalable Parallel Classifier for Data Mi.pdf:/home/rp152k/Zotero/storage/CSMRSFHV/Shafer et al. - SPRINT A Scalable Parallel Classifier for Data Mi.pdf:application/pdf},
}

@article{liu_clustering_nodate,
	title = {Clustering {Via} {Decision} {Tree} {Construction}},
	language = {en},
	author = {Liu, Bing and Xia, Yiyuan and Yu, Philip S},
	pages = {25},
	file = {Liu et al. - Clustering Via Decision Tree Construction.pdf:/home/rp152k/Zotero/storage/S8RGBKQT/Liu et al. - Clustering Via Decision Tree Construction.pdf:application/pdf},
}

@article{chen_big_2020,
	title = {Big {Self}-{Supervised} {Models} are {Strong} {Semi}-{Supervised} {Learners}},
	url = {http://arxiv.org/abs/2006.10029},
	abstract = {One paradigm for learning from few labeled examples while making best use of a large amount of unlabeled data is unsupervised pretraining followed by supervised fine-tuning. Although this paradigm uses unlabeled data in a task-agnostic way, in contrast to common approaches to semi-supervised learning for computer vision, we show that it is surprisingly effective for semi-supervised learning on ImageNet. A key ingredient of our approach is the use of big (deep and wide) networks during pretraining and fine-tuning. We find that, the fewer the labels, the more this approach (task-agnostic use of unlabeled data) benefits from a bigger network. After fine-tuning, the big network can be further improved and distilled into a much smaller one with little loss in classification accuracy by using the unlabeled examples for a second time, but in a task-specific way. The proposed semi-supervised learning algorithm can be summarized in three steps: unsupervised pretraining of a big ResNet model using SimCLRv2, supervised fine-tuning on a few labeled examples, and distillation with unlabeled examples for refining and transferring the task-specific knowledge. This procedure achieves 73.9\% ImageNet top-1 accuracy with just 1\% of the labels (\${\textbackslash}le\$13 labeled images per class) using ResNet-50, a \$10{\textbackslash}times\$ improvement in label efficiency over the previous state-of-the-art. With 10\% of labels, ResNet-50 trained with our method achieves 77.5\% top-1 accuracy, outperforming standard supervised training with all of the labels.},
	urldate = {2021-05-26},
	journal = {arXiv:2006.10029 [cs, stat]},
	author = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.10029},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: NeurIPS'2020. Code and pretrained models at https://github.com/google-research/simclr},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/QMG8JMSQ/Chen et al. - 2020 - Big Self-Supervised Models are Strong Semi-Supervi.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/T5JJEDAS/2006.html:text/html},
}

@article{oord_representation_2019,
	title = {Representation {Learning} with {Contrastive} {Predictive} {Coding}},
	url = {http://arxiv.org/abs/1807.03748},
	abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
	urldate = {2021-05-25},
	journal = {arXiv:1807.03748 [cs, stat]},
	author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	month = jan,
	year = {2019},
	note = {arXiv: 1807.03748
version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/CM5QM55U/Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/IKL8KTFS/1807.html:text/html},
}

@article{park_contrastive_2020,
	title = {Contrastive {Learning} for {Unpaired} {Image}-to-{Image} {Translation}},
	url = {http://arxiv.org/abs/2007.15651},
	abstract = {In image-to-image translation, each patch in the output should reflect the content of the corresponding patch in the input, independent of domain. We propose a straightforward method for doing so -- maximizing mutual information between the two, using a framework based on contrastive learning. The method encourages two elements (corresponding patches) to map to a similar point in a learned feature space, relative to other elements (other patches) in the dataset, referred to as negatives. We explore several critical design choices for making contrastive learning effective in the image synthesis setting. Notably, we use a multilayer, patch-based approach, rather than operate on entire images. Furthermore, we draw negatives from within the input image itself, rather than from the rest of the dataset. We demonstrate that our framework enables one-sided translation in the unpaired image-to-image translation setting, while improving quality and reducing training time. In addition, our method can even be extended to the training setting where each "domain" is only a single image.},
	urldate = {2021-05-24},
	journal = {arXiv:2007.15651 [cs]},
	author = {Park, Taesung and Efros, Alexei A. and Zhang, Richard and Zhu, Jun-Yan},
	month = aug,
	year = {2020},
	note = {arXiv: 2007.15651},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: ECCV 2020. Please visit https://taesungp.github.io/ContrastiveUnpairedTranslation/ for introduction videos and more. v3 contains typo fixes and citation update},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/DRPQKEW6/Park et al. - 2020 - Contrastive Learning for Unpaired Image-to-Image T.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/IJYK88WN/2007.html:text/html},
}

@article{zhu_unpaired_2020,
	title = {Unpaired {Image}-to-{Image} {Translation} using {Cycle}-{Consistent} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1703.10593},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain \$X\$ to a target domain \$Y\$ in the absence of paired examples. Our goal is to learn a mapping \$G: X {\textbackslash}rightarrow Y\$ such that the distribution of images from \$G(X)\$ is indistinguishable from the distribution \$Y\$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping \$F: Y {\textbackslash}rightarrow X\$ and introduce a cycle consistency loss to push \$F(G(X)) {\textbackslash}approx X\$ (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	urldate = {2021-05-23},
	journal = {arXiv:1703.10593 [cs]},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	month = aug,
	year = {2020},
	note = {arXiv: 1703.10593},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: An extended version of our ICCV 2017 paper, v7 fixed the typos and updated the implementation details. Code and data: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/KSRXCALI/Zhu et al. - 2020 - Unpaired Image-to-Image Translation using Cycle-Co.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/ALARMCP8/1703.html:text/html;Full Text:/home/rp152k/Zotero/storage/RV4Q7ZFZ/Zhu et al. - 2020 - Unpaired Image-to-Image Translation using Cycle-Co.pdf:application/pdf},
}

@article{lehtinen_noise2noise_2018,
	title = {{Noise2Noise}: {Learning} {Image} {Restoration} without {Clean} {Data}},
	shorttitle = {{Noise2Noise}},
	url = {http://arxiv.org/abs/1803.04189},
	abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning -- learning to map corrupted observations to clean signals -- with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans -- all corrupted by different processes -- based on noisy data only.},
	urldate = {2021-05-23},
	journal = {arXiv:1803.04189 [cs, stat]},
	author = {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
	month = oct,
	year = {2018},
	note = {arXiv: 1803.04189
version: 3},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Added link to official implementation and updated MRI results to match it},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/MGYCLR2N/Lehtinen et al. - 2018 - Noise2Noise Learning Image Restoration without Cl.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/WHBR4TGH/1803.html:text/html},
}

@article{zhou_w2s_2020,
	title = {{W2S}: {Microscopy} {Data} with {Joint} {Denoising} and {Super}-{Resolution} for {Widefield} to {SIM} {Mapping}},
	shorttitle = {{W2S}},
	url = {http://arxiv.org/abs/2003.05961},
	abstract = {In fluorescence microscopy live-cell imaging, there is a critical trade-off between the signal-to-noise ratio and spatial resolution on one side, and the integrity of the biological sample on the other side. To obtain clean high-resolution (HR) images, one can either use microscopy techniques, such as structured-illumination microscopy (SIM), or apply denoising and super-resolution (SR) algorithms. However, the former option requires multiple shots that can damage the samples, and although efficient deep learning based algorithms exist for the latter option, no benchmark exists to evaluate these algorithms on the joint denoising and SR (JDSR) tasks. To study JDSR on microscopy data, we propose such a novel JDSR dataset, Widefield2SIM (W2S), acquired using a conventional fluorescence widefield and SIM imaging. W2S includes 144,000 real fluorescence microscopy images, resulting in a total of 360 sets of images. A set is comprised of noisy low-resolution (LR) widefield images with different noise levels, a noise-free LR image, and a corresponding high-quality HR SIM image. W2S allows us to benchmark the combinations of 6 denoising methods and 6 SR methods. We show that state-of-the-art SR networks perform very poorly on noisy inputs. Our evaluation also reveals that applying the best denoiser in terms of reconstruction error followed by the best SR method does not necessarily yield the best final result. Both quantitative and qualitative results show that SR networks are sensitive to noise and the sequential application of denoising and SR algorithms is sub-optimal. Lastly, we demonstrate that SR networks retrained end-to-end for JDSR outperform any combination of state-of-the-art deep denoising and SR networks},
	urldate = {2021-05-23},
	journal = {arXiv:2003.05961 [cs, eess]},
	author = {Zhou, Ruofan and Helou, Majed El and Sage, Daniel and Laroche, Thierry and Seitz, Arne and Süsstrunk, Sabine},
	month = aug,
	year = {2020},
	note = {arXiv: 2003.05961},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: ECCVW 2020. Project page: {\textbackslash}},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/462ERVYC/Zhou et al. - 2020 - W2S Microscopy Data with Joint Denoising and Supe.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/IDUJMPMT/2003.html:text/html},
}

@misc{noauthor_ixi_nodate,
	title = {{IXI} {Dataset} – {Brain} {Development}},
	url = {http://brain-development.org/ixi-dataset/},
	language = {en-US},
	urldate = {2021-05-23},
	file = {Snapshot:/home/rp152k/Zotero/storage/WHL5W3SD/ixi-dataset.html:text/html},
}

@article{zhang_poisson-gaussian_2019,
	title = {A {Poisson}-{Gaussian} {Denoising} {Dataset} with {Real} {Fluorescence} {Microscopy} {Images}},
	url = {http://arxiv.org/abs/1812.10366},
	abstract = {Fluorescence microscopy has enabled a dramatic development in modern biology. Due to its inherently weak signal, fluorescence microscopy is not only much noisier than photography, but also presented with Poisson-Gaussian noise where Poisson noise, or shot noise, is the dominating noise source. To get clean fluorescence microscopy images, it is highly desirable to have effective denoising algorithms and datasets that are specifically designed to denoise fluorescence microscopy images. While such algorithms exist, no such datasets are available. In this paper, we fill this gap by constructing a dataset - the Fluorescence Microscopy Denoising (FMD) dataset - that is dedicated to Poisson-Gaussian denoising. The dataset consists of 12,000 real fluorescence microscopy images obtained with commercial confocal, two-photon, and wide-field microscopes and representative biological samples such as cells, zebrafish, and mouse brain tissues. We use image averaging to effectively obtain ground truth images and 60,000 noisy images with different noise levels. We use this dataset to benchmark 10 representative denoising algorithms and find that deep learning methods have the best performance. To our knowledge, this is the first real microscopy image dataset for Poisson-Gaussian denoising purposes and it could be an important tool for high-quality, real-time denoising applications in biomedical research.},
	urldate = {2021-05-23},
	journal = {arXiv:1812.10366 [cs, eess, stat]},
	author = {Zhang, Yide and Zhu, Yinhao and Nichols, Evan and Wang, Qingfei and Zhang, Siyuan and Smith, Cody and Howard, Scott},
	month = apr,
	year = {2019},
	note = {arXiv: 1812.10366},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: Camera-ready version for CVPR 2019. The Fluorescence Microscopy Denoising (FMD) dataset is available at https://drive.google.com/drive/folders/1aygMzSDdoq63IqSk-ly8cMq0\_owup8UM},
	file = {arXiv Fulltext PDF:/home/rp152k/Zotero/storage/Z8F3K8VP/Zhang et al. - 2019 - A Poisson-Gaussian Denoising Dataset with Real Flu.pdf:application/pdf;arXiv.org Snapshot:/home/rp152k/Zotero/storage/QV8H6RY4/1812.html:text/html},
}

@misc{saraswathi_exposition_2024,
	title = {An {Exposition} of {Pathfinding} {Strategies} {Within} {Lightning} {Network} {Clients}},
	url = {http://arxiv.org/abs/2410.13784},
	doi = {10.48550/arXiv.2410.13784},
	abstract = {The Lightning Network is a peer-to-peer network designed to address Bitcoin's scalability challenges, facilitating rapid, cost-effective, and instantaneous transactions through bidirectional, blockchain-backed payment channels among network peers. Due to a source-based routing of payments, different pathfinding strategies are used in practice, trading off different objectives for each other such as payment reliability and routing fees. This paper explores differences within pathfinding strategies used by prominent Lightning Network node implementations, which include different underlying cost functions and different constraints, as well as different greedy algorithms of shortest path-type. Surprisingly, we observe that the pathfinding problems that most LN node implementations attempt to solve are NP-complete, and cannot be guaranteed to be optimally solved by the variants of Dijkstra's algorithm currently deployed in production. Through comparative analysis and simulations, we evaluate efficacy of different pathfinding strategies across metrics such as success rate, fees, path length, and timelock. Our experiments indicate that the strategies used by LND tend to be advantageous in terms of payment reliability, Eclair tends to result in paths with low fees, and that LDK exhibits average reliability with larger fee levels for smaller payment amounts; furthermore, CLN stands out for its minimal timelock paths. Additionally, we investigate the impact of Lightning node connectivity levels on routing efficiency. The findings of our analysis provide insights towards future improvements of pathfinding strategies and algorithms used within the Lightning Network.},
	urldate = {2024-10-20},
	publisher = {arXiv},
	author = {Saraswathi, Sindura and Kümmerle, Christian},
	month = oct,
	year = {2024},
	note = {arXiv:2410.13784},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Networking and Internet Architecture, Computer Science - Social and Information Networks},
	file = {Preprint PDF:/home/rp152k/Zotero/storage/D93TB9XV/Saraswathi and Kümmerle - 2024 - An Exposition of Pathfinding Strategies Within Lightning Network Clients.pdf:application/pdf;Snapshot:/home/rp152k/Zotero/storage/84R97B25/2410.html:text/html},
}

@misc{zhang_how_2017,
	title = {How {Better} is {Distributed} {SDN}? {An} {Analytical} {Approach}},
	shorttitle = {How {Better} is {Distributed} {SDN}?},
	url = {http://arxiv.org/abs/1712.04161},
	doi = {10.48550/arXiv.1712.04161},
	abstract = {Distributed software-defined networks (SDN), consisting of multiple inter-connected network domains, each managed by one SDN controller, is an emerging networking architecture that offers balanced centralized control and distributed operations. Under such networking paradigm, most existing works focus on designing sophisticated controller-synchronization strategies to improve joint controller-decision-making for inter-domain routing. However, there is still a lack of fundamental understanding of how the performance of distributed SDN is related to network attributes, thus impossible to justify the necessity of complicated strategies. In this regard, we analyze and quantify the performance enhancement of distributed SDN architectures, influenced by intra-/inter-domain synchronization levels and network structural properties. Based on a generic weighted network model, we establish analytical methods for performance estimation under four synchronization scenarios with increasing synchronization cost. Moreover, two of these synchronization scenarios correspond to extreme cases, i.e., minimum/maximum synchronization, which are, therefore, capable of bounding the performance of distributed SDN with any given synchronization levels. Our theoretical results reveal how network performance is related to synchronization levels and inter-domain connections, the accuracy of which are confirmed by simulations based on both real and synthetic networks. To the best of our knowledge, this is the first work quantifying the performance of distributed SDN analytically, which provides fundamental guidance for future SDN protocol designs and performance estimation.},
	urldate = {2024-10-21},
	publisher = {arXiv},
	author = {Zhang, Ziyao and Ma, Liang and Leung, Kin K. and Le, Franck and Kompella, Sastry and Tassiulas, Leandros},
	month = dec,
	year = {2017},
	note = {arXiv:1712.04161},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Preprint PDF:/home/rp152k/Zotero/storage/7KLSRPMI/Zhang et al. - 2017 - How Better is Distributed SDN An Analytical Approach.pdf:application/pdf;Snapshot:/home/rp152k/Zotero/storage/8ITYSS5B/1712.html:text/html},
}

@article{armbrust_lakehouse_2021,
	title = {Lakehouse: {A} {New} {Generation} of {Open} {Platforms} that {Unify} {Data} {Warehousing} and {Advanced} {Analytics}},
	abstract = {This paper argues that the data warehouse architecture as we know it today will wither in the coming years and be replaced by a new architectural pattern, the Lakehouse, which will (i) be based on open direct-access data formats, such as Apache Parquet, (ii) have firstclass support for machine learning and data science, and (iii) offer state-of-the-art performance. Lakehouses can help address several major challenges with data warehouses, including data staleness, reliability, total cost of ownership, data lock-in, and limited use-case support. We discuss how the industry is already moving toward Lakehouses and how this shift may affect work in data management. We also report results from a Lakehouse system using Parquet that is competitive with popular cloud data warehouses on TPC-DS.},
	language = {en},
	author = {Armbrust, Michael and Ghodsi, Ali and Xin, Reynold and Zaharia, Matei},
	year = {2021},
	file = {PDF:/home/rp152k/Zotero/storage/N8XFR3UK/Armbrust et al. - 2021 - Lakehouse A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics.pdf:application/pdf},
}
