:PROPERTIES:
:ID:       51dfb5e7-6b00-4bde-b5f5-65cb395f5d54
:END:
#+title: Llammaindex
#+filetags: :ai:tool:

* RAG Concepts
** Loading Stage
*** Connector (aka Reader)
 - ingests data from different sources into Documents and Nodes
*** Documents
 - container around any data source
*** Nodes
 - atomic unit of data : a chunk of the source doc
** Indexing Stage
*** Indexes
- once ingested, llamaindex will help you index data into a structure that is easy to retrieve.
- The index is actually a managed map between the node metadata and the vector embeddings
*** Embeddings
- vector representations of data for similarity searches
** Querying Stage
*** Retrievers
 - A retriever defines to how to efficiently retrieve relevant context from an index when given a query
 - the retrieval strategy dictates the relevancy of data and the efficiency of doing so.
*** Routers
 - a router determines which retriever will be used to retrieve relevant context from the knowledge base.
*** Node PostProcessors
 - A node postprocessor takes in a set of retrieved nodes and applies transformatoins, filtering or re-ranking logic to them.
*** Response Synthesizers
 - A response synthesizer generates a respone from an LLM, using a user query and a given set of retrieved text chunks.
* Index Types

 - SummaryIndex: This is very similar to a box for recipes – it keeps your Nodes in order, so you can access them one by one. It takes in a set of documents, chunks them up into Nodes, and then concatenates them into a list. It’s great for reading through a big Document.

 - DocumentSummaryIndex: This constructs a concise summary for each document, mapping these summaries back to their respective nodes. It facilitates efficient information retrieval by using these summaries to quickly identify relevant documents.

 - VectorStoreIndex: This is one of the more sophisticated types of indexes and probably the workhorse in most RAG applications. It converts text into vector embeddings and uses math to group similar Nodes, helping locate Nodes that are alike.

 - TreeIndex: The perfect solution for those who love order. This index behaves similarly to putting smaller boxes inside bigger ones, organizing Nodes by levels in a tree-like structure. Inside, each parent node stores summaries of the children nodes. These are generated by the LLM, using a general summarization prompt. This particular index can be very useful for summarization.

 - KeywordTableIndex: Imagine you need to find a dish by the ingredients you have. The keyword index connects important words to the Nodes they’re in. It makes finding any node easy by looking up keywords.

 - KnowledgeGraphIndex: This is useful when you need to link facts in a big network of data stored as a knowledge graph. This one is good for answering tricky questions about lots of connected information.

 - ComposableGraph: This allows you to create complex index structures in which Document- level indexes are indexed in higher-level collections. That’s right: you can even build an index of indexes if you want

* Relevant Nodes
** [[id:d9d30a75-f1aa-4ca0-8480-cb617afe29ab][Deep Lake Vector Stores]]
** [[id:29c7a4c9-2699-4c8c-b2f2-a8e9bd5731ce][Ragas]]
** [[id:a8c2f397-3380-4aae-a771-63a4b688d4fe][DeepEval]]
** [[id:9c288e43-1136-4bf5-9d12-26ada642224b][Vector Store Index]]
** [[id:94432c86-f87e-427f-94e5-40247fe807cb][Ollama]]
** [[id:4bc04402-bf24-4740-aba6-1ff667bd5247][LocalAI]]
* Resources
- https://www.llamaindex.ai/
