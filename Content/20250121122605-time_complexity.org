:PROPERTIES:
:ID:       8e9f6cef-da57-48ed-b86d-029f1b528615
:END:
#+title: Time Complexity
#+filetags: :programming:


* Overview

- *Definition of Time Complexity*: A computational complexity that describes the amount of time it takes to run an algorithm as a function of the length of the input.

- *Big O Notation*: Provides an upper bound on the time complexity, allowing for worst-case scenario analysis. Common notations include:
  - O(1): Constant time
  - O(log n): Logarithmic time
  - O(n): Linear time
  - O(n log n): Linearithmic time
  - O(n^2): Quadratic time
  - O(2^n): Exponential time

- [[id:b9d4742e-ffa3-465a-aba1-2133db03abd3][Complexity Classes]]:
  - P: Problems that can be solved in polynomial time.
  - NP: Problems for which solutions can be verified in polynomial time.
  - NP-complete: Hardest problems in NP, which if solved in polynomial time would imply P = NP.


*** Questions for Further Clarification:
- What specific algorithm or data structure are you focusing on in the context of time complexity?
- Are there particular properties of time complexity (e.g., average case vs. worst case) you wish to explore further?

*** Pathways for Further Research:
- How do different data structures (arrays, linked lists, trees) impact time complexity?
- In what scenarios do average case complexities differ significantly from worst-case analyses?
- What are the implications of time complexity in real-time systems versus batch processing systems?


* Complexity Bounds

- Upper Bound: This is represented as Big O notation (e.g., O(n)), indicating the maximum amount of time an algorithm may take to complete.

- Lower Bound: Represented as Big Omega notation (e.g., Ω(n)), which indicates the minimum time necessary for a given algorithm for every input size.

- Tight Bound: Denoted as Big Theta notation (e.g., Θ(n)), which describes both the upper and lower bounds of an algorithm, providing an accurate characterization of performance.

- [[id:b91e378d-b17a-43b2-b13e-19c02afe1558][Amortized Complexity]]: Average case over a sequence of operations. It is useful for data structures that may have occasional expensive operations (e.g., dynamic array resizing).

- [[id:95edc4bc-c364-4b18-833a-ba476b3283e8][Recursive Algorithms]]: Time complexities for recursive algorithms often derive from the [[id:97440bc5-79a0-4140-9066-8a95ac747fd9][Master Theorem]] or recurrence relations to determine their performance characteristics.
